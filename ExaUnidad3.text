import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.SparkSession
import org.apache.log4j._

val spark = SparkSession.builder().getOrCreate()

val data  = spark.read.option("header","true").option("inferSchema", "true").format("csv").load("sale.csv")

data.printSchema()

data.head(1)
data.show()

import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}

val assembler = (new VectorAssembler().setInputCols(Array("Fresh","Milk", "Grocery","Frozen","Detergents_Paper","Delicassen")).setOutputCol("features"))

val df = assembler.transform(data)
df.show(5)
val ft = df.select(df("features"))
import org.apache.spark.ml.clustering.KMeans
val kmeans = new KMeans().setK(3).setSeed(1L)

val df = assembler.transform(data)

val ft = df.select(df("features"))

val model = kmeans.fit(ft)

val WSSE = model.computeCost(ft)


println(s"Within set sum of Squared Errors = $WSSE")
println("Cluster Centers: ")
Cluster Centers:
model.clusterCenters.foreach(println)
